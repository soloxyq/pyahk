#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""æ­¥éª¤6: ç”Ÿæˆæ•°å­—æ¨¡æ¿ - ä»æ ‡æ³¨æ•°æ®æå–æœ€ä½³æ ·æœ¬ç”Ÿæˆæ¨¡æ¿"""

import os
import sys
from pathlib import Path
import json
import numpy as np
import cv2
from collections import defaultdict

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from deepai.config import DATA_DIR


# æ¨¡æ¿é…ç½®
TEMPLATE_DIR = "game_char_templates/hp_mp_digits"
SAMPLES_PER_CHAR = 5  # æ¯ä¸ªå­—ç¬¦ä¿ç•™çš„æ ·æœ¬æ•°
MIN_CONFIDENCE = 0.95  # æœ€ä½ç½®ä¿¡åº¦é˜ˆå€¼


def load_labeled_data(labels_path):
    """åŠ è½½æ ‡æ³¨æ•°æ®"""
    print(f"\n{'='*80}")
    print(f"ğŸ“Š åŠ è½½æ ‡æ³¨æ•°æ®")
    print(f"{'='*80}")
    
    with open(labels_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    # è¿‡æ»¤é«˜è´¨é‡çš„å·²æ ‡æ³¨æ•°æ®
    high_quality_data = []
    for d in data:
        if (d.get('label') and 
            len(d['label']) == 1 and 
            d.get('confidence', 0) >= MIN_CONFIDENCE):
            high_quality_data.append(d)
    
    print(f"æ€»æ•°æ®: {len(data)}")
    print(f"é«˜è´¨é‡æ•°æ® (ç½®ä¿¡åº¦â‰¥{MIN_CONFIDENCE}): {len(high_quality_data)}")
    
    if len(high_quality_data) < 50:
        print(f"âš ï¸ è­¦å‘Š: é«˜è´¨é‡æ•°æ®ä¸è¶³ï¼Œå»ºè®®é™ä½ç½®ä¿¡åº¦é˜ˆå€¼æˆ–å¢åŠ æ•°æ®")
    
    return high_quality_data


def group_by_label(data):
    """æŒ‰æ ‡ç­¾åˆ†ç»„æ•°æ®"""
    print(f"\n{'='*80}")
    print(f"ğŸ”¤ æŒ‰å­—ç¬¦åˆ†ç»„")
    print(f"{'='*80}")
    
    grouped = defaultdict(list)
    for d in data:
        label = d['label']
        grouped[label].append(d)
    
    # æŒ‰ç½®ä¿¡åº¦æ’åº
    for label in grouped:
        grouped[label].sort(key=lambda x: x.get('confidence', 0), reverse=True)
    
    print(f"å­—ç¬¦ç»Ÿè®¡:")
    for label, samples in sorted(grouped.items()):
        print(f"  '{label}': {len(samples)} æ ·æœ¬")
    
    return grouped


def select_best_samples(grouped_data, samples_per_char):
    """ä¸ºæ¯ä¸ªå­—ç¬¦é€‰æ‹©æœ€ä½³æ ·æœ¬"""
    print(f"\n{'='*80}")
    print(f"â­ é€‰æ‹©æœ€ä½³æ ·æœ¬ (æ¯å­—ç¬¦{samples_per_char}ä¸ª)")
    print(f"{'='*80}")
    
    selected = {}
    
    for label, samples in sorted(grouped_data.items()):
        # é€‰æ‹©å‰Nä¸ªé«˜ç½®ä¿¡åº¦æ ·æœ¬
        best_samples = samples[:samples_per_char]
        
        # å¦‚æœæ ·æœ¬ä¸è¶³ï¼Œä½¿ç”¨æ‰€æœ‰æ ·æœ¬
        if len(best_samples) < samples_per_char:
            print(f"âš ï¸ '{label}': åªæœ‰ {len(best_samples)} ä¸ªæ ·æœ¬ (éœ€è¦{samples_per_char}ä¸ª)")
        
        selected[label] = best_samples
        
        avg_confidence = np.mean([s['confidence'] for s in best_samples])
        print(f"  '{label}': {len(best_samples)} æ ·æœ¬, å¹³å‡ç½®ä¿¡åº¦: {avg_confidence:.2%}")
    
    return selected


def normalize_template(img):
    """æ ‡å‡†åŒ–æ¨¡æ¿å›¾åƒ"""
    # å·²ç»æ˜¯äºŒå€¼åŒ–çš„å›¾åƒï¼Œåªéœ€è¦ç¡®ä¿å°ºå¯¸åˆé€‚
    # å¯ä»¥é€‰æ‹©ç»Ÿä¸€å°ºå¯¸æˆ–ä¿æŒåŸå§‹å°ºå¯¸
    
    # æ–¹æ¡ˆ1: ä¿æŒåŸå§‹å°ºå¯¸ï¼ˆæ¨èï¼Œä¿ç•™ç»†èŠ‚ï¼‰
    return img
    
    # æ–¹æ¡ˆ2: ç»Ÿä¸€å°ºå¯¸ï¼ˆå¦‚æœéœ€è¦ï¼‰
    # target_height = 28
    # h, w = img.shape
    # scale = target_height / h
    # new_w = int(w * scale)
    # return cv2.resize(img, (new_w, target_height), interpolation=cv2.INTER_AREA)


def save_templates(selected_samples, output_dir):
    """ä¿å­˜æ¨¡æ¿å›¾åƒ"""
    print(f"\n{'='*80}")
    print(f"ğŸ’¾ ä¿å­˜æ¨¡æ¿")
    print(f"{'='*80}")
    
    os.makedirs(output_dir, exist_ok=True)
    
    total_saved = 0
    
    for label, samples in sorted(selected_samples.items()):
        # ä¸ºæ–œæ åˆ›å»ºç‰¹æ®Šç›®å½•å
        char_dir_name = "slash" if label == '/' else label
        char_dir = os.path.join(output_dir, char_dir_name)
        os.makedirs(char_dir, exist_ok=True)
        
        for idx, sample in enumerate(samples):
            img_path = sample['image_path']
            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
            
            if img is None:
                continue
            
            # æ ‡å‡†åŒ–æ¨¡æ¿
            normalized = normalize_template(img)
            
            # ä¿å­˜æ¨¡æ¿
            template_name = f"template_{idx:02d}.png"
            template_path = os.path.join(char_dir, template_name)
            cv2.imwrite(template_path, normalized)
            
            total_saved += 1
        
        print(f"  '{label}' ({char_dir_name}): {len(samples)} ä¸ªæ¨¡æ¿")
    
    print(f"\nâœ… æ€»å…±ä¿å­˜ {total_saved} ä¸ªæ¨¡æ¿åˆ°: {output_dir}")


def create_template_info(selected_samples, output_dir):
    """åˆ›å»ºæ¨¡æ¿ä¿¡æ¯æ–‡ä»¶"""
    info = {
        "description": "HP/MPæ•°å­—è¯†åˆ«æ¨¡æ¿",
        "generated_from": "DeepAIè®­ç»ƒæ•°æ®",
        "min_confidence": MIN_CONFIDENCE,
        "samples_per_char": SAMPLES_PER_CHAR,
        "characters": {},
        "total_templates": 0
    }
    
    for label, samples in sorted(selected_samples.items()):
        char_dir_name = "slash" if label == '/' else label
        info["characters"][label] = {
            "directory": char_dir_name,
            "num_templates": len(samples),
            "avg_confidence": float(np.mean([s['confidence'] for s in samples])),
            "min_confidence": float(min([s['confidence'] for s in samples])),
            "max_confidence": float(max([s['confidence'] for s in samples]))
        }
        info["total_templates"] += len(samples)
    
    # ä¿å­˜ä¿¡æ¯æ–‡ä»¶
    info_path = os.path.join(output_dir, "template_info.json")
    with open(info_path, 'w', encoding='utf-8') as f:
        json.dump(info, f, indent=2, ensure_ascii=False)
    
    print(f"æ¨¡æ¿ä¿¡æ¯å·²ä¿å­˜: {info_path}")


def create_readme(output_dir, selected_samples):
    """åˆ›å»ºREADMEæ–‡æ¡£"""
    readme_content = f"""# HP/MP æ•°å­—è¯†åˆ«æ¨¡æ¿

æœ¬ç›®å½•åŒ…å«ä»DeepAIè®­ç»ƒæ•°æ®è‡ªåŠ¨ç”Ÿæˆçš„æ•°å­—æ¨¡æ¿ã€‚

## ğŸ“Š æ¨¡æ¿ç»Ÿè®¡

"""
    
    for label, samples in sorted(selected_samples.items()):
        char_dir_name = "slash" if label == '/' else label
        avg_conf = np.mean([s['confidence'] for s in samples])
        readme_content += f"- **'{label}'** ({char_dir_name}/): {len(samples)} ä¸ªæ¨¡æ¿, å¹³å‡ç½®ä¿¡åº¦: {avg_conf:.2%}\n"
    
    readme_content += f"""
## ğŸ“ ç›®å½•ç»“æ„

```
hp_mp_digits/
â”œâ”€â”€ README.md           # æœ¬æ–‡æ¡£
â”œâ”€â”€ template_info.json  # æ¨¡æ¿å…ƒæ•°æ®
â”œâ”€â”€ 0/                  # æ•°å­— 0 çš„æ¨¡æ¿
â”‚   â”œâ”€â”€ template_00.png
â”‚   â”œâ”€â”€ template_01.png
â”‚   â””â”€â”€ ...
â”œâ”€â”€ 1/                  # æ•°å­— 1 çš„æ¨¡æ¿
â”œâ”€â”€ ...
â”œâ”€â”€ 9/                  # æ•°å­— 9 çš„æ¨¡æ¿
â””â”€â”€ slash/              # æ–œæ  / çš„æ¨¡æ¿
```

## ğŸ¯ ä½¿ç”¨æ–¹æ³•

### åœ¨ä¸»ç¨‹åºä¸­ä½¿ç”¨

1. æ‰“å¼€ä¸»ç¨‹åº
2. è¿›å…¥ **èµ„æºç®¡ç†** é…ç½®
3. è®¾ç½® **HP/MPæ£€æµ‹æ¨¡å¼** ä¸º **æ–‡æœ¬OCR**
4. åœ¨ **OCRå¼•æ“** ä¸‹æ‹‰æ¡†ä¸­é€‰æ‹© **æ•°å­—æ¨¡æ¿**
5. æµ‹è¯•è¯†åˆ«æ•ˆæœ

### æ€§èƒ½ç‰¹ç‚¹

- âœ… æ— éœ€é¢å¤–ä¾èµ–
- âœ… é€Ÿåº¦ä¸­ç­‰ï¼ˆ50-80msï¼‰
- âœ… å‡†ç¡®ç‡è‰¯å¥½ï¼ˆ90-95%ï¼‰
- âš ï¸ éœ€è¦ä¸€æ¬¡è®­ç»ƒç”Ÿæˆæ¨¡æ¿

## ğŸ”„ é‡æ–°ç”Ÿæˆæ¨¡æ¿

å¦‚æœéœ€è¦é‡æ–°ç”Ÿæˆæ¨¡æ¿ï¼š

```bash
# åˆ é™¤ç°æœ‰æ¨¡æ¿
Remove-Item -Recurse -Force game_char_templates/hp_mp_digits

# é‡æ–°è¿è¡Œç”Ÿæˆè„šæœ¬
python deepai/scripts/06_generate_digit_templates.py
```

## ğŸ“Š ä¸å…¶ä»–è¯†åˆ«æ–¹å¼å¯¹æ¯”

| è¯†åˆ«æ–¹å¼ | é€Ÿåº¦ | å‡†ç¡®ç‡ | ä¾èµ– |
|---------|------|--------|------|
| **Tesseract** | 240ms | 100% | tesseract.exe |
| **æ•°å­—æ¨¡æ¿** | 50-80ms | 90-95% | æ—  |
| **TFLite** | 8-12ms | >98% | tflite-runtime |

## ğŸ› ï¸ æ¨¡æ¿è´¨é‡

- **æœ€ä½ç½®ä¿¡åº¦**: {MIN_CONFIDENCE}
- **æ¯å­—ç¬¦æ ·æœ¬æ•°**: {SAMPLES_PER_CHAR}
- **æ¥æº**: ä»æ¸¸æˆå½•åˆ¶è§†é¢‘è‡ªåŠ¨æå–

## ğŸ’¡ æç¤º

- å¦‚æœè¯†åˆ«ä¸å‡†ç¡®ï¼Œå¯ä»¥å¢åŠ è®­ç»ƒæ•°æ®å¹¶é‡æ–°ç”Ÿæˆæ¨¡æ¿
- å¦‚æœè¿½æ±‚æè‡´æ€§èƒ½ï¼Œå»ºè®®ä½¿ç”¨TFLiteå¼•æ“
- å¦‚æœè¿½æ±‚ç¨³å®šå¯é ï¼Œå»ºè®®ä½¿ç”¨Tesseractå¼•æ“
"""
    
    readme_path = os.path.join(output_dir, "README.md")
    with open(readme_path, 'w', encoding='utf-8') as f:
        f.write(readme_content)
    
    print(f"READMEå·²ä¿å­˜: {readme_path}")


def visualize_templates(selected_samples, output_dir):
    """ç”Ÿæˆæ¨¡æ¿å¯è§†åŒ–å›¾åƒ"""
    print(f"\n{'='*80}")
    print(f"ğŸ“¸ ç”Ÿæˆæ¨¡æ¿é¢„è§ˆ")
    print(f"{'='*80}")
    
    import matplotlib.pyplot as plt
    
    labels = sorted(selected_samples.keys())
    num_labels = len(labels)
    
    fig, axes = plt.subplots(num_labels, SAMPLES_PER_CHAR, 
                             figsize=(SAMPLES_PER_CHAR * 2, num_labels * 2))
    
    if num_labels == 1:
        axes = axes.reshape(1, -1)
    
    for i, label in enumerate(labels):
        samples = selected_samples[label]
        for j in range(SAMPLES_PER_CHAR):
            ax = axes[i, j]
            
            if j < len(samples):
                img_path = samples[j]['image_path']
                img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
                
                if img is not None:
                    ax.imshow(img, cmap='gray')
                    confidence = samples[j]['confidence']
                    ax.set_title(f"'{label}' {confidence:.2%}", fontsize=10)
                else:
                    ax.text(0.5, 0.5, 'N/A', ha='center', va='center')
            else:
                ax.text(0.5, 0.5, 'N/A', ha='center', va='center')
            
            ax.axis('off')
    
    plt.tight_layout()
    preview_path = os.path.join(output_dir, "templates_preview.png")
    plt.savefig(preview_path, dpi=150, bbox_inches='tight')
    print(f"âœ… æ¨¡æ¿é¢„è§ˆå·²ä¿å­˜: {preview_path}")


def main():
    """ä¸»å‡½æ•°"""
    print(f"\n{'='*80}")
    print(f"ğŸš€ æ•°å­—æ¨¡æ¿ç”Ÿæˆæµç¨‹")
    print(f"{'='*80}\n")
    
    # æ£€æŸ¥æ ‡æ³¨æ•°æ®
    labels_path = os.path.join(DATA_DIR, 'labels.json')
    if not os.path.exists(labels_path):
        print(f"âŒ é”™è¯¯: æ ‡æ³¨æ–‡ä»¶ä¸å­˜åœ¨ - {labels_path}")
        print(f"è¯·å…ˆè¿è¡Œæ•°æ®å‡†å¤‡è„šæœ¬: python deepai/scripts/01_prepare_data.py")
        return
    
    # åŠ è½½æ•°æ®
    data = load_labeled_data(labels_path)
    
    if len(data) < 50:
        print(f"\nâŒ é”™è¯¯: é«˜è´¨é‡æ•°æ®ä¸è¶³ï¼ˆè‡³å°‘éœ€è¦50ä¸ªï¼‰")
        print(f"å»ºè®®:")
        print(f"  1. å¢åŠ è®­ç»ƒæ•°æ®ï¼ˆå½•åˆ¶æ›´é•¿çš„è§†é¢‘ï¼‰")
        print(f"  2. è¿è¡Œæ ‡æ³¨éªŒè¯å·¥å…·æé«˜æ ‡æ³¨è´¨é‡")
        print(f"  3. é™ä½ç½®ä¿¡åº¦é˜ˆå€¼ï¼ˆä¿®æ”¹è„šæœ¬ä¸­çš„MIN_CONFIDENCEï¼‰")
        return
    
    # æŒ‰æ ‡ç­¾åˆ†ç»„
    grouped_data = group_by_label(data)
    
    # æ£€æŸ¥å­—ç¬¦å®Œæ•´æ€§
    required_chars = set('0123456789/')
    found_chars = set(grouped_data.keys())
    missing_chars = required_chars - found_chars
    
    if missing_chars:
        print(f"\nâš ï¸ è­¦å‘Š: ç¼ºå°‘ä»¥ä¸‹å­—ç¬¦çš„æ•°æ®: {missing_chars}")
        print(f"å»ºè®®å¢åŠ è®­ç»ƒæ•°æ®ä»¥è¦†ç›–æ‰€æœ‰å­—ç¬¦")
    
    # é€‰æ‹©æœ€ä½³æ ·æœ¬
    selected_samples = select_best_samples(grouped_data, SAMPLES_PER_CHAR)
    
    # ä¿å­˜æ¨¡æ¿
    save_templates(selected_samples, TEMPLATE_DIR)
    
    # åˆ›å»ºæ¨¡æ¿ä¿¡æ¯
    create_template_info(selected_samples, TEMPLATE_DIR)
    
    # åˆ›å»ºREADME
    create_readme(TEMPLATE_DIR, selected_samples)
    
    # ç”Ÿæˆé¢„è§ˆ
    try:
        visualize_templates(selected_samples, TEMPLATE_DIR)
    except Exception as e:
        print(f"âš ï¸ è­¦å‘Š: é¢„è§ˆç”Ÿæˆå¤±è´¥ - {e}")
    
    print(f"\n{'='*80}")
    print(f"âœ… æ¨¡æ¿ç”Ÿæˆå®Œæˆ!")
    print(f"{'='*80}")
    print(f"\nç”Ÿæˆçš„æ–‡ä»¶:")
    print(f"  æ¨¡æ¿ç›®å½•: {TEMPLATE_DIR}")
    print(f"  æ¨¡æ¿ä¿¡æ¯: {os.path.join(TEMPLATE_DIR, 'template_info.json')}")
    print(f"  è¯´æ˜æ–‡æ¡£: {os.path.join(TEMPLATE_DIR, 'README.md')}")
    print(f"  é¢„è§ˆå›¾åƒ: {os.path.join(TEMPLATE_DIR, 'templates_preview.png')}")
    print(f"\nä¸‹ä¸€æ­¥: åœ¨ä¸»ç¨‹åºä¸­é€‰æ‹©'æ•°å­—æ¨¡æ¿'å¼•æ“æµ‹è¯•æ•ˆæœ")
    print(f"{'='*80}\n")


if __name__ == "__main__":
    main()
