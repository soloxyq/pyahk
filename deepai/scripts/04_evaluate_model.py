#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""æ­¥éª¤4: æ¨¡å‹è¯„ä¼° - è¯¦ç»†è¯„ä¼°æ¨¡å‹æ€§èƒ½"""

import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'

import sys
from pathlib import Path
import json
import numpy as np
import cv2
import tensorflow as tf
from tensorflow import keras
from sklearn.metrics import confusion_matrix, classification_report
import matplotlib.pyplot as plt
import seaborn as sns
import time

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from deepai.config import *


def load_model_and_labels():
    """åŠ è½½æ¨¡å‹å’Œæ ‡ç­¾æ˜ å°„"""
    print(f"\n{'='*80}")
    print(f"ğŸ“¦ åŠ è½½æ¨¡å‹")
    print(f"{'='*80}")
    
    if not os.path.exists(MODEL_SAVE_PATH):
        print(f"âŒ é”™è¯¯: æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ - {MODEL_SAVE_PATH}")
        return None, None
    
    model = keras.models.load_model(MODEL_SAVE_PATH)
    print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ: {MODEL_SAVE_PATH}")
    
    label_map_path = os.path.join(MODELS_DIR, 'label_map.json')
    with open(label_map_path, 'r', encoding='utf-8') as f:
        idx_to_label = json.load(f)
    
    # è½¬æ¢é”®ä¸ºæ•´æ•°
    idx_to_label = {int(k): v for k, v in idx_to_label.items()}
    
    print(f"âœ… æ ‡ç­¾æ˜ å°„åŠ è½½æˆåŠŸ")
    print(f"ç±»åˆ«æ•°: {len(idx_to_label)}")
    print(f"æ ‡ç­¾: {sorted(idx_to_label.values())}\n")
    
    return model, idx_to_label


def load_test_data(labels_path, idx_to_label):
    """åŠ è½½æµ‹è¯•æ•°æ®"""
    print(f"\n{'='*80}")
    print(f"ğŸ“Š åŠ è½½æµ‹è¯•æ•°æ®")
    print(f"{'='*80}")
    
    with open(labels_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    # è¿‡æ»¤å·²æ ‡æ³¨çš„æ•°æ®
    labeled_data = [d for d in data if d.get('label') and len(d['label']) == 1]
    
    # åˆ›å»ºåå‘æ˜ å°„
    label_to_idx = {v: k for k, v in idx_to_label.items()}
    
    images = []
    labels = []
    
    for d in labeled_data:
        img_path = d['image_path']
        label = d['label']
        
        if label not in label_to_idx:
            continue
        
        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
        if img is None:
            continue
        
        img_resized = cv2.resize(img, (IMG_WIDTH, IMG_HEIGHT), interpolation=cv2.INTER_AREA)
        img_normalized = img_resized.astype(np.float32) / 255.0
        
        images.append(img_normalized)
        labels.append(label_to_idx[label])
    
    images = np.array(images)
    labels = np.array(labels)
    images = np.expand_dims(images, axis=-1)
    
    print(f"æµ‹è¯•æ•°æ®: {images.shape[0]} æ ·æœ¬")
    print(f"âœ… åŠ è½½å®Œæˆ!\n")
    
    return images, labels


def evaluate_performance(model, X_test, y_test, idx_to_label):
    """è¯„ä¼°æ€§èƒ½"""
    print(f"\n{'='*80}")
    print(f"âš¡ æ€§èƒ½æµ‹è¯•")
    print(f"{'='*80}")
    
    # é¢„æµ‹ï¼ˆæµ‹é‡æ—¶é—´ï¼‰
    start_time = time.time()
    y_pred = model.predict(X_test, verbose=0)
    end_time = time.time()
    
    total_time = (end_time - start_time) * 1000  # è½¬æ¢ä¸ºæ¯«ç§’
    avg_time = total_time / len(X_test)
    
    print(f"æ€»é¢„æµ‹æ—¶é—´: {total_time:.2f} ms")
    print(f"å•ä¸ªé¢„æµ‹: {avg_time:.2f} ms")
    print(f"é¢„æµ‹é€Ÿåº¦: {1000/avg_time:.1f} æ¬¡/ç§’")
    
    # HP/MPä¸€èµ·è¯†åˆ«çš„æ—¶é—´ï¼ˆå‡è®¾5ä¸ªå­—ç¬¦ï¼‰
    hp_mp_time = avg_time * 5
    print(f"\nHP/MPè¯†åˆ«æ—¶é—´(5ä¸ªå­—ç¬¦): {hp_mp_time:.2f} ms")
    
    y_pred_classes = np.argmax(y_pred, axis=1)
    
    # å‡†ç¡®ç‡
    accuracy = np.mean(y_pred_classes == y_test)
    print(f"\næ€»ä½“å‡†ç¡®ç‡: {accuracy:.2%}")
    
    print(f"âœ… æ€§èƒ½æµ‹è¯•å®Œæˆ!\n")
    
    return y_pred_classes, y_pred


def plot_confusion_matrix(y_test, y_pred_classes, idx_to_label, save_path):
    """ç»˜åˆ¶æ··æ·†çŸ©é˜µ"""
    print(f"ğŸ“Š ç”Ÿæˆæ··æ·†çŸ©é˜µ...")
    
    cm = confusion_matrix(y_test, y_pred_classes)
    
    labels = [idx_to_label[i] for i in sorted(idx_to_label.keys())]
    
    plt.figure(figsize=(10, 8))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                xticklabels=labels, yticklabels=labels)
    plt.title('æ··æ·†çŸ©é˜µ')
    plt.ylabel('çœŸå®æ ‡ç­¾')
    plt.xlabel('é¢„æµ‹æ ‡ç­¾')
    plt.tight_layout()
    plt.savefig(save_path)
    print(f"âœ… æ··æ·†çŸ©é˜µå·²ä¿å­˜: {save_path}\n")


def print_classification_report(y_test, y_pred_classes, idx_to_label):
    """æ‰“å°åˆ†ç±»æŠ¥å‘Š"""
    print(f"\n{'='*80}")
    print(f"ğŸ“‹ åˆ†ç±»æŠ¥å‘Š")
    print(f"{'='*80}\n")
    
    labels = [idx_to_label[i] for i in sorted(idx_to_label.keys())]
    
    report = classification_report(y_test, y_pred_classes, 
                                   target_names=labels, digits=4)
    print(report)


def analyze_errors(X_test, y_test, y_pred_classes, y_pred, idx_to_label, save_dir):
    """åˆ†æé”™è¯¯æ ·æœ¬"""
    print(f"\n{'='*80}")
    print(f"ğŸ” é”™è¯¯åˆ†æ")
    print(f"{'='*80}")
    
    errors_dir = os.path.join(save_dir, 'errors')
    os.makedirs(errors_dir, exist_ok=True)
    
    # æ‰¾å‡ºé”™è¯¯æ ·æœ¬
    error_indices = np.where(y_pred_classes != y_test)[0]
    
    print(f"é”™è¯¯æ ·æœ¬æ•°: {len(error_indices)}/{len(y_test)}")
    
    if len(error_indices) == 0:
        print(f"âœ… æ²¡æœ‰é”™è¯¯æ ·æœ¬!\n")
        return
    
    # ä¿å­˜å‰20ä¸ªé”™è¯¯æ ·æœ¬
    num_show = min(20, len(error_indices))
    
    fig, axes = plt.subplots(4, 5, figsize=(15, 12))
    axes = axes.ravel()
    
    for i in range(num_show):
        idx = error_indices[i]
        img = X_test[idx].squeeze()
        true_label = idx_to_label[y_test[idx]]
        pred_label = idx_to_label[y_pred_classes[idx]]
        confidence = y_pred[idx][y_pred_classes[idx]]
        
        axes[i].imshow(img, cmap='gray')
        axes[i].set_title(f"çœŸå®: '{true_label}'\né¢„æµ‹: '{pred_label}'\nç½®ä¿¡åº¦: {confidence:.2%}", 
                         fontsize=10)
        axes[i].axis('off')
    
    # éšè—å¤šä½™çš„å­å›¾
    for i in range(num_show, 20):
        axes[i].axis('off')
    
    plt.tight_layout()
    error_plot_path = os.path.join(errors_dir, 'error_samples.png')
    plt.savefig(error_plot_path)
    print(f"âœ… é”™è¯¯æ ·æœ¬å·²ä¿å­˜: {error_plot_path}\n")


def test_inference_speed(model, idx_to_label):
    """æµ‹è¯•æ¨ç†é€Ÿåº¦"""
    print(f"\n{'='*80}")
    print(f"ğŸš€ æ¨ç†é€Ÿåº¦æµ‹è¯•")
    print(f"{'='*80}")
    
    # åˆ›å»ºéšæœºæµ‹è¯•æ•°æ®
    test_sizes = [1, 5, 10, 50, 100]
    
    print(f"æµ‹è¯•ä¸åŒæ‰¹æ¬¡å¤§å°çš„æ¨ç†é€Ÿåº¦:\n")
    
    for size in test_sizes:
        dummy_input = np.random.rand(size, IMG_HEIGHT, IMG_WIDTH, 1).astype(np.float32)
        
        # é¢„çƒ­
        model.predict(dummy_input, verbose=0)
        
        # æµ‹è¯•
        times = []
        for _ in range(10):
            start = time.time()
            model.predict(dummy_input, verbose=0)
            end = time.time()
            times.append((end - start) * 1000)
        
        avg_time = np.mean(times)
        std_time = np.std(times)
        per_sample = avg_time / size
        
        print(f"  æ‰¹æ¬¡å¤§å° {size:3d}: {avg_time:6.2f} Â± {std_time:5.2f} ms "
              f"(å•ä¸ª: {per_sample:.2f} ms, {1000/per_sample:.0f} æ¬¡/ç§’)")
    
    print(f"\nâœ… é€Ÿåº¦æµ‹è¯•å®Œæˆ!\n")


def main():
    """ä¸»å‡½æ•°"""
    print(f"\n{'='*80}")
    print(f"ğŸ” DeepAI æ¨¡å‹è¯„ä¼°")
    print(f"{'='*80}\n")
    
    # åŠ è½½æ¨¡å‹
    model, idx_to_label = load_model_and_labels()
    if model is None:
        return
    
    # åŠ è½½æµ‹è¯•æ•°æ®
    labels_path = os.path.join(DATA_DIR, 'labels.json')
    X_test, y_test = load_test_data(labels_path, idx_to_label)
    
    # è¯„ä¼°æ€§èƒ½
    y_pred_classes, y_pred = evaluate_performance(model, X_test, y_test, idx_to_label)
    
    # æ··æ·†çŸ©é˜µ
    cm_path = os.path.join(MODELS_DIR, 'confusion_matrix.png')
    plot_confusion_matrix(y_test, y_pred_classes, idx_to_label, cm_path)
    
    # åˆ†ç±»æŠ¥å‘Š
    print_classification_report(y_test, y_pred_classes, idx_to_label)
    
    # é”™è¯¯åˆ†æ
    analyze_errors(X_test, y_test, y_pred_classes, y_pred, idx_to_label, MODELS_DIR)
    
    # æ¨ç†é€Ÿåº¦æµ‹è¯•
    test_inference_speed(model, idx_to_label)
    
    print(f"\n{'='*80}")
    print(f"âœ… è¯„ä¼°å®Œæˆ!")
    print(f"{'='*80}")
    print(f"\nç”Ÿæˆçš„æ–‡ä»¶:")
    print(f"  æ··æ·†çŸ©é˜µ: {cm_path}")
    print(f"  é”™è¯¯æ ·æœ¬: {os.path.join(MODELS_DIR, 'errors/error_samples.png')}")
    print(f"\nä¸‹ä¸€æ­¥: é›†æˆåˆ°åº”ç”¨ä¸­")
    print(f"  ä½¿ç”¨ torchlight_assistant/utils/cnn_digit_recognizer.py")
    print(f"{'='*80}\n")


if __name__ == "__main__":
    main()
