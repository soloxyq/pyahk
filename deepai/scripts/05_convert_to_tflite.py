#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""æ­¥éª¤5: æ¨¡å‹è½¬æ¢ - å°†TensorFlowæ¨¡å‹è½¬æ¢ä¸ºTFLiteæ ¼å¼"""

import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'

import sys
from pathlib import Path
import json
import numpy as np
import cv2
import tensorflow as tf
from tensorflow import keras

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from deepai.config import *


def load_test_data(labels_path, idx_to_label):
    """åŠ è½½æµ‹è¯•æ•°æ®ï¼ˆç”¨äºéªŒè¯è½¬æ¢åçš„å‡†ç¡®ç‡ï¼‰"""
    print(f"\n{'='*80}")
    print(f"ğŸ“Š åŠ è½½æµ‹è¯•æ•°æ®")
    print(f"{'='*80}")
    
    with open(labels_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    # è¿‡æ»¤å·²æ ‡æ³¨çš„æ•°æ®
    labeled_data = [d for d in data if d.get('label') and len(d['label']) == 1]
    
    # åˆ›å»ºåå‘æ˜ å°„
    label_to_idx = {v: k for k, v in idx_to_label.items()}
    
    images = []
    labels = []
    
    for d in labeled_data[:100]:  # åªç”¨100ä¸ªæ ·æœ¬æµ‹è¯•
        img_path = d['image_path']
        label = d['label']
        
        if label not in label_to_idx:
            continue
        
        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
        if img is None:
            continue
        
        img_resized = cv2.resize(img, (IMG_WIDTH, IMG_HEIGHT), interpolation=cv2.INTER_AREA)
        img_normalized = img_resized.astype(np.float32) / 255.0
        
        images.append(img_normalized)
        labels.append(label_to_idx[label])
    
    images = np.array(images)
    labels = np.array(labels)
    images = np.expand_dims(images, axis=-1)
    
    print(f"æµ‹è¯•æ•°æ®: {images.shape[0]} æ ·æœ¬")
    print(f"âœ… åŠ è½½å®Œæˆ!\n")
    
    return images, labels


def convert_to_tflite(model_path, output_path, quantize=True):
    """è½¬æ¢æ¨¡å‹ä¸ºTFLiteæ ¼å¼"""
    print(f"\n{'='*80}")
    print(f"ğŸ”„ è½¬æ¢æ¨¡å‹ä¸ºTFLite")
    print(f"{'='*80}")
    
    # åŠ è½½Kerasæ¨¡å‹
    print(f"åŠ è½½æ¨¡å‹: {model_path}")
    model = keras.models.load_model(model_path)
    
    # åˆ›å»ºè½¬æ¢å™¨
    converter = tf.lite.TFLiteConverter.from_keras_model(model)
    
    if quantize:
        print(f"å¯ç”¨é‡åŒ–ä¼˜åŒ–...")
        # åŠ¨æ€èŒƒå›´é‡åŒ–ï¼ˆæ— éœ€ä»£è¡¨æ€§æ•°æ®é›†ï¼‰
        converter.optimizations = [tf.lite.Optimize.DEFAULT]
        
        # å¯é€‰ï¼šä½¿ç”¨float16é‡åŒ–ï¼ˆæ›´å¥½çš„ç²¾åº¦/å¤§å°å¹³è¡¡ï¼‰
        # converter.target_spec.supported_types = [tf.float16]
    
    # è½¬æ¢
    print(f"å¼€å§‹è½¬æ¢...")
    tflite_model = converter.convert()
    
    # ä¿å­˜
    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    with open(output_path, 'wb') as f:
        f.write(tflite_model)
    
    # æ˜¾ç¤ºå¤§å°ä¿¡æ¯
    original_size = os.path.getsize(model_path) / 1024
    tflite_size = os.path.getsize(output_path) / 1024
    compression_ratio = (1 - tflite_size / original_size) * 100
    
    print(f"\nâœ… è½¬æ¢å®Œæˆ!")
    print(f"åŸå§‹æ¨¡å‹å¤§å°: {original_size:.2f} KB")
    print(f"TFLiteæ¨¡å‹å¤§å°: {tflite_size:.2f} KB")
    print(f"å‹ç¼©ç‡: {compression_ratio:.1f}%")
    print(f"ä¿å­˜è·¯å¾„: {output_path}\n")
    
    return tflite_model


def test_tflite_model(tflite_path, test_images, test_labels, idx_to_label):
    """æµ‹è¯•TFLiteæ¨¡å‹çš„å‡†ç¡®ç‡"""
    print(f"\n{'='*80}")
    print(f"ğŸ§ª æµ‹è¯•TFLiteæ¨¡å‹")
    print(f"{'='*80}")
    
    # åŠ è½½TFLiteæ¨¡å‹
    interpreter = tf.lite.Interpreter(model_path=tflite_path)
    interpreter.allocate_tensors()
    
    # è·å–è¾“å…¥è¾“å‡ºå¼ é‡ä¿¡æ¯
    input_details = interpreter.get_input_details()
    output_details = interpreter.get_output_details()
    
    print(f"è¾“å…¥å½¢çŠ¶: {input_details[0]['shape']}")
    print(f"è¾“å‡ºå½¢çŠ¶: {output_details[0]['shape']}")
    
    # æµ‹è¯•æ¨ç†
    correct = 0
    total = len(test_images)
    
    import time
    times = []
    
    for i, (img, true_label) in enumerate(zip(test_images, test_labels)):
        # å‡†å¤‡è¾“å…¥
        input_data = np.expand_dims(img, axis=0).astype(np.float32)
        
        # æ¨ç†
        interpreter.set_tensor(input_details[0]['index'], input_data)
        
        start = time.time()
        interpreter.invoke()
        end = time.time()
        times.append((end - start) * 1000)
        
        # è·å–è¾“å‡º
        output_data = interpreter.get_tensor(output_details[0]['index'])
        pred_label = np.argmax(output_data[0])
        
        if pred_label == true_label:
            correct += 1
    
    accuracy = correct / total
    avg_time = np.mean(times)
    
    print(f"\næµ‹è¯•ç»“æœ:")
    print(f"  å‡†ç¡®ç‡: {accuracy:.2%} ({correct}/{total})")
    print(f"  å¹³å‡æ¨ç†æ—¶é—´: {avg_time:.2f} ms")
    print(f"  HP+MPé¢„ä¼°æ—¶é—´: {avg_time * 5:.2f} ms (5ä¸ªå­—ç¬¦)")
    print(f"âœ… æµ‹è¯•å®Œæˆ!\n")
    
    return accuracy, avg_time


def create_model_info(model_path, tflite_path, accuracy, inference_time):
    """åˆ›å»ºæ¨¡å‹ä¿¡æ¯æ–‡ä»¶"""
    info = {
        "model_type": "TFLite",
        "original_model": os.path.basename(model_path),
        "tflite_model": os.path.basename(tflite_path),
        "original_size_kb": os.path.getsize(model_path) / 1024,
        "tflite_size_kb": os.path.getsize(tflite_path) / 1024,
        "test_accuracy": f"{accuracy:.2%}",
        "avg_inference_time_ms": f"{inference_time:.2f}",
        "hp_mp_time_ms": f"{inference_time * 5:.2f}",
        "image_size": [IMG_WIDTH, IMG_HEIGHT],
        "num_classes": 11,
        "classes": "0-9 and /",
        "quantized": True,
        "optimization": "Dynamic range quantization",
        "framework": "TensorFlow Lite",
        "runtime": "tflite-runtime",
        "created_date": __import__('datetime').datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    }
    
    info_path = os.path.join(MODELS_DIR, 'model_info.json')
    with open(info_path, 'w', encoding='utf-8') as f:
        json.dump(info, f, indent=2, ensure_ascii=False)
    
    print(f"æ¨¡å‹ä¿¡æ¯å·²ä¿å­˜: {info_path}")


def main():
    """ä¸»å‡½æ•°"""
    print(f"\n{'='*80}")
    print(f"ğŸš€ TFLite æ¨¡å‹è½¬æ¢æµç¨‹")
    print(f"{'='*80}\n")
    
    # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
    if not os.path.exists(MODEL_SAVE_PATH):
        print(f"âŒ é”™è¯¯: æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ - {MODEL_SAVE_PATH}")
        print(f"è¯·å…ˆè¿è¡Œè®­ç»ƒè„šæœ¬: python deepai/scripts/03_train_model.py")
        return
    
    # åŠ è½½æ ‡ç­¾æ˜ å°„
    label_map_path = os.path.join(MODELS_DIR, 'label_map.json')
    with open(label_map_path, 'r', encoding='utf-8') as f:
        idx_to_label = json.load(f)
    idx_to_label = {int(k): v for k, v in idx_to_label.items()}
    
    # å®šä¹‰è¾“å‡ºè·¯å¾„
    tflite_path = os.path.join(MODELS_DIR, 'digit_cnn.tflite')
    
    # è½¬æ¢æ¨¡å‹
    tflite_model = convert_to_tflite(
        MODEL_SAVE_PATH, 
        tflite_path, 
        quantize=True
    )
    
    # åŠ è½½æµ‹è¯•æ•°æ®
    labels_path = os.path.join(DATA_DIR, 'labels.json')
    test_images, test_labels = load_test_data(labels_path, idx_to_label)
    
    # æµ‹è¯•TFLiteæ¨¡å‹
    accuracy, inference_time = test_tflite_model(
        tflite_path, 
        test_images, 
        test_labels, 
        idx_to_label
    )
    
    # åˆ›å»ºæ¨¡å‹ä¿¡æ¯æ–‡ä»¶
    create_model_info(MODEL_SAVE_PATH, tflite_path, accuracy, inference_time)
    
    print(f"\n{'='*80}")
    print(f"âœ… è½¬æ¢æµç¨‹å®Œæˆ!")
    print(f"{'='*80}")
    print(f"\nç”Ÿæˆçš„æ–‡ä»¶:")
    print(f"  TFLiteæ¨¡å‹: {tflite_path}")
    print(f"  æ¨¡å‹ä¿¡æ¯: {os.path.join(MODELS_DIR, 'model_info.json')}")
    print(f"\nä¸‹ä¸€æ­¥: åœ¨ä¸»ç¨‹åºä¸­ä½¿ç”¨TFLiteå¼•æ“")
    print(f"  1. å®‰è£…ä¾èµ–: pip install tflite-runtime")
    print(f"  2. åœ¨UIä¸­é€‰æ‹© 'TFLite' å¼•æ“")
    print(f"  3. äº«å—{inference_time * 5:.1f}msçš„è¯†åˆ«é€Ÿåº¦!")
    print(f"{'='*80}\n")


if __name__ == "__main__":
    main()
