#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""DeepAIè¯†åˆ«å™¨ - æä¾›ä¸‰ç§è¯†åˆ«å¼•æ“çš„ç»Ÿä¸€æ¥å£"""

import sys
import numpy as np
import cv2
import json
from pathlib import Path
from typing import Dict, List, Optional, Tuple

try:
    import tensorflow as tf
    from tensorflow import keras

    TENSORFLOW_AVAILABLE = True
except ImportError:
    TENSORFLOW_AVAILABLE = False


class KerasDigitRecognizer:
    """Kerasæ•°å­—è¯†åˆ«å™¨ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰"""

    _instance = None

    def __new__(cls):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
            cls._instance._initialized = False
        return cls._instance

    def __init__(self):
        if getattr(self, "_initialized", False):
            return

        self.model: Optional[keras.Model] = None
        self.idx_to_label: Optional[Dict[int, str]] = None
        self.img_width = 28
        self.img_height = 28
        self._initialized = False
        self._model_timestamp = None  # è®°å½•æ¨¡å‹æ–‡ä»¶çš„ä¿®æ”¹æ—¶é—´

        self.project_root = Path(__file__).resolve().parent.parent
        self.models_dir = self.project_root / "deepai" / "models"

    def initialize(
        self, model_path: Optional[str] = None, label_map_path: Optional[str] = None, force_reload: bool = False
    ) -> bool:
        """åˆå§‹åŒ–è¯†åˆ«å™¨
        
        Args:
            model_path: æ¨¡å‹æ–‡ä»¶è·¯å¾„
            label_map_path: æ ‡ç­¾æ˜ å°„æ–‡ä»¶è·¯å¾„
            force_reload: æ˜¯å¦å¼ºåˆ¶é‡æ–°åŠ è½½æ¨¡å‹
        """
        if self._initialized and not force_reload:
            # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦è¢«æ›´æ–°
            if self._check_model_updated():
                print("ğŸ”„ æ£€æµ‹åˆ°æ¨¡å‹æ–‡ä»¶å·²æ›´æ–°ï¼Œé‡æ–°åŠ è½½...")
                force_reload = True
            else:
                return True
        
        if force_reload:
            self._initialized = False

        if not TENSORFLOW_AVAILABLE:
            print("âŒ TensorFlowæœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install tensorflow")
            return False

        try:
            found_model_path = self._find_model(model_path)
            if not found_model_path:
                return False

            label_map_path = label_map_path or self.models_dir / "label_map.json"
            if not Path(label_map_path).exists():
                print(f"âŒ æ ‡ç­¾æ˜ å°„ä¸å­˜åœ¨: {label_map_path}")
                return False

            # åŠ è½½Kerasæ¨¡å‹
            self.model = keras.models.load_model(str(found_model_path))
            
            # è®°å½•æ¨¡å‹æ–‡ä»¶çš„ä¿®æ”¹æ—¶é—´
            self._model_path = found_model_path
            self._model_timestamp = found_model_path.stat().st_mtime

            # åŠ è½½æ ‡ç­¾æ˜ å°„
            with open(label_map_path, "r", encoding="utf-8") as f:
                self.idx_to_label = {int(k): v for k, v in json.load(f).items()}

            # é¢„çƒ­æ¨¡å‹ï¼ˆè§¦å‘å›¾ç¼–è¯‘ï¼Œé¿å…é¦–æ¬¡æ¨ç†æ…¢ï¼‰
            dummy_input = np.zeros((1, self.img_height, self.img_width, 1), dtype=np.float32)
            self.model.predict(dummy_input, verbose=0)

            self._initialized = True
            print(f"âœ… Kerasæ¨¡å‹åˆå§‹åŒ–æˆåŠŸ: {found_model_path.name}")
            return True

        except Exception as e:
            print(f"âŒ Kerasæ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}")
            return False
    
    def _check_model_updated(self) -> bool:
        """æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦è¢«æ›´æ–°"""
        if not hasattr(self, '_model_path') or not hasattr(self, '_model_timestamp'):
            return False
        
        if not self._model_path.exists():
            return False
        
        current_timestamp = self._model_path.stat().st_mtime
        return current_timestamp > self._model_timestamp

    def _find_model(self, model_path: Optional[str]) -> Optional[Path]:
        """æŸ¥æ‰¾æ¨¡å‹æ–‡ä»¶ï¼ˆ.kerasæˆ–.h5ï¼‰"""
        if model_path:
            p = Path(model_path)
            if p.exists():
                print(f"âœ… ä½¿ç”¨æŒ‡å®šæ¨¡å‹: {p}")
                return p

        # ä¼˜å…ˆä½¿ç”¨.kerasæ ¼å¼
        user_model_keras = self.models_dir / "digit_cnn.keras"
        if user_model_keras.exists():
            print(f"âœ… ä½¿ç”¨ç”¨æˆ·è®­ç»ƒçš„Kerasæ¨¡å‹: {user_model_keras.name}")
            return user_model_keras

        # å…¼å®¹æ—§çš„.h5æ ¼å¼
        user_model_h5 = self.models_dir / "digit_cnn.h5"
        if user_model_h5.exists():
            print(f"âœ… ä½¿ç”¨ç”¨æˆ·è®­ç»ƒçš„H5æ¨¡å‹: {user_model_h5.name}")
            return user_model_h5

        print(f"âŒ æœªæ‰¾åˆ°æ¨¡å‹æ–‡ä»¶ (.keras æˆ– .h5)")
        print(f"   è¯·å…ˆè¿è¡Œè®­ç»ƒè„šæœ¬: python deepai/scripts/03_train_model.py")
        return None

    def preprocess_image(self, img: np.ndarray) -> np.ndarray:
        """é¢„å¤„ç†å›¾åƒï¼Œé€šè¿‡å¼€è¿ç®—å»é™¤é€—å·ç­‰å™ªç‚¹"""
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) if len(img.shape) == 3 else img
        upscaled = cv2.resize(gray, None, fx=3, fy=3, interpolation=cv2.INTER_CUBIC)
        _, binary = cv2.threshold(upscaled, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)

        # ä½¿ç”¨2x2çš„æ ¸è¿›è¡Œå¼€è¿ç®—ï¼Œå¯ä»¥æœ‰æ•ˆå»é™¤é€—å·å’Œå°çš„å™ªç‚¹
        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))
        opened = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel, iterations=1)

        return opened

    def segment_digits(
        self, binary: np.ndarray, min_width: int = 6, min_height: int = 10
    ) -> List[np.ndarray]:
        """åˆ†å‰²å•ä¸ªæ•°å­—"""
        contours, _ = cv2.findContours(
            binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE
        )
        boxes = sorted(
            [
                cv2.boundingRect(c)
                for c in contours
                if cv2.boundingRect(c)[2] >= min_width
                and cv2.boundingRect(c)[3] >= min_height
            ],
            key=lambda b: b[0],
        )
        return [binary[y : y + h, x : x + w] for x, y, w, h in boxes]

    def recognize_digit(self, digit_img: np.ndarray) -> Tuple[Optional[str], float]:
        """è¯†åˆ«å•ä¸ªæ•°å­—"""
        if not self._initialized or self.model is None:
            return None, 0.0

        try:
            resized = cv2.resize(
                digit_img,
                (self.img_width, self.img_height),
                interpolation=cv2.INTER_AREA,
            )
            normalized = resized.astype(np.float32) / 255.0
            input_data = np.expand_dims(normalized, axis=(0, -1))

            output = self.model.predict(input_data, verbose=0)[0]

            pred_idx = int(np.argmax(output))
            if self.idx_to_label is None:
                return None, 0.0
            return self.idx_to_label.get(pred_idx), float(output[pred_idx])

        except Exception as e:
            print(f"âŒ Kerasè¯†åˆ«å¤±è´¥: {e}")
            return None, 0.0

    def recognize_digits_batch(self, digit_imgs: List[np.ndarray]) -> List[Tuple[Optional[str], float]]:
        """æ‰¹é‡è¯†åˆ«å¤šä¸ªæ•°å­—ï¼ˆæ€§èƒ½ä¼˜åŒ–ï¼‰"""
        if not self._initialized or self.model is None:
            return [(None, 0.0)] * len(digit_imgs)

        if not digit_imgs:
            return []

        try:
            # æ‰¹é‡é¢„å¤„ç†
            batch_data = []
            for digit_img in digit_imgs:
                resized = cv2.resize(
                    digit_img,
                    (self.img_width, self.img_height),
                    interpolation=cv2.INTER_AREA,
                )
                normalized = resized.astype(np.float32) / 255.0
                batch_data.append(normalized)

            # æ‰¹é‡æ¨ç†ï¼ˆä¸€æ¬¡æ€§å¤„ç†æ‰€æœ‰æ•°å­—ï¼‰
            batch_input = np.array(batch_data)[..., np.newaxis]
            outputs = self.model.predict(batch_input, verbose=0)

            # è§£æç»“æœ
            results = []
            for output in outputs:
                pred_idx = int(np.argmax(output))
                if self.idx_to_label is None:
                    results.append((None, 0.0))
                else:
                    results.append((self.idx_to_label.get(pred_idx), float(output[pred_idx])))

            return results

        except Exception as e:
            print(f"âŒ Kerasæ‰¹é‡è¯†åˆ«å¤±è´¥: {e}")
            return [(None, 0.0)] * len(digit_imgs)

    def recognize_and_parse(
        self, img: np.ndarray
    ) -> Tuple[Optional[int], Optional[int]]:
        """è¯†åˆ«å¹¶è§£æHP/MPæ•°å­—ï¼ˆæ ¼å¼ï¼š123/456ï¼‰"""
        if not self._initialized:
            return None, None

        try:
            binary = self.preprocess_image(img)
            digit_images = self.segment_digits(binary)

            if not digit_images:
                return None, None

            # ä½¿ç”¨æ‰¹é‡è¯†åˆ«ï¼ˆæ€§èƒ½ä¼˜åŒ–ï¼‰
            results = self.recognize_digits_batch(digit_images)
            result = "".join([label for label, _ in results if label])

            if "/" in result:
                parts = result.split("/", 1)
                if len(parts) == 2:
                    try:
                        current = int(parts[0].replace(",", ""))
                        maximum = int(parts[1].replace(",", ""))
                        return current, maximum
                    except ValueError:
                        pass
            return None, None

        except Exception as e:
            print(f"âŒ Kerasè§£æå¤±è´¥: {e}")
            return None, None


class TemplateDigitRecognizer:
    """æ¨¡æ¿åŒ¹é…æ•°å­—è¯†åˆ«å™¨ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰"""

    _instance = None

    def __new__(cls):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
            cls._instance._initialized = False
        return cls._instance

    def __init__(self):
        if getattr(self, "_initialized", False):
            return

        self.templates: Dict[str, np.ndarray] = {}  # æ¯ä¸ªå­—ç¬¦åªæœ‰ä¸€ä¸ªæ¨¡æ¿
        self._initialized = False

        self.project_root = Path(__file__).resolve().parent.parent
        self.templates_dir = self.project_root / "game_char_templates"

    def initialize(self, templates_dir: Optional[str] = None) -> bool:
        """åˆå§‹åŒ–è¯†åˆ«å™¨"""
        if self._initialized:
            return True

        try:
            templates_path = Path(templates_dir) if templates_dir else self.templates_dir
            
            if not templates_path.exists():
                print(f"âŒ æ¨¡æ¿ç›®å½•ä¸å­˜åœ¨: {templates_path}")
                return False

            # åŠ è½½å•æ¨¡æ¿æ–‡ä»¶ï¼ˆæ ¼å¼ï¼štemplate_0_11x16.png, template_slash_6x16.pngï¼‰
            template_files = list(templates_path.glob("template_*.png"))
            
            if not template_files:
                print(f"âŒ æœªæ‰¾åˆ°æ¨¡æ¿æ–‡ä»¶ï¼ˆæ ¼å¼ï¼štemplate_X_WxH.pngï¼‰")
                return False
            
            template_count = 0
            
            for template_file in template_files:
                # è§£ææ–‡ä»¶å
                name = template_file.stem  # å»æ‰ .png
                parts = name.split('_')
                
                if len(parts) < 2:
                    continue
                
                # è·å–å­—ç¬¦æ ‡ç­¾
                label = parts[1]
                if label == 'slash':
                    label = '/'
                
                # åŠ è½½æ¨¡æ¿å›¾åƒ
                img = cv2.imread(str(template_file), cv2.IMREAD_GRAYSCALE)
                if img is not None:
                    self.templates[label] = img
                    template_count += 1

            if not self.templates:
                print(f"âŒ æœªæ‰¾åˆ°ä»»ä½•æœ‰æ•ˆæ¨¡æ¿")
                return False

            self._initialized = True
            print(f"âœ… æ¨¡æ¿è¯†åˆ«å™¨åˆå§‹åŒ–æˆåŠŸ: åŠ è½½äº† {template_count} ä¸ªæ¨¡æ¿")
            print(f"   å­—ç¬¦: {sorted(self.templates.keys())}")
            return True

        except Exception as e:
            print(f"âŒ æ¨¡æ¿è¯†åˆ«å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            return False

    def preprocess_image(self, img: np.ndarray) -> np.ndarray:
        """é¢„å¤„ç†å›¾åƒ"""
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) if len(img.shape) == 3 else img
        upscaled = cv2.resize(gray, None, fx=3, fy=3, interpolation=cv2.INTER_CUBIC)
        _, binary = cv2.threshold(upscaled, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))
        opened = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel, iterations=1)
        return opened

    def segment_digits(
        self, binary: np.ndarray, min_width: int = 6, min_height: int = 10
    ) -> List[np.ndarray]:
        """åˆ†å‰²å•ä¸ªæ•°å­—"""
        contours, _ = cv2.findContours(
            binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE
        )
        boxes = sorted(
            [
                cv2.boundingRect(c)
                for c in contours
                if cv2.boundingRect(c)[2] >= min_width
                and cv2.boundingRect(c)[3] >= min_height
            ],
            key=lambda b: b[0],
        )
        return [binary[y : y + h, x : x + w] for x, y, w, h in boxes]

    def recognize_digit(self, digit_img: np.ndarray) -> Tuple[Optional[str], float]:
        """è¯†åˆ«å•ä¸ªæ•°å­—"""
        if not self._initialized:
            return None, 0.0

        try:
            best_label = None
            best_score = 0.0

            for label, template in self.templates.items():
                # è°ƒæ•´å¤§å°åŒ¹é…
                resized = cv2.resize(digit_img, (template.shape[1], template.shape[0]))
                
                # æ¨¡æ¿åŒ¹é…
                result = cv2.matchTemplate(resized, template, cv2.TM_CCOEFF_NORMED)
                score = result[0][0]
                
                if score > best_score:
                    best_score = score
                    best_label = label

            return best_label, float(best_score)

        except Exception as e:
            print(f"âŒ æ¨¡æ¿è¯†åˆ«å¤±è´¥: {e}")
            return None, 0.0

    def recognize_and_parse(
        self, img: np.ndarray
    ) -> Tuple[Optional[int], Optional[int]]:
        """è¯†åˆ«å¹¶è§£æHP/MPæ•°å­—ï¼ˆæ ¼å¼ï¼š123/456ï¼‰"""
        if not self._initialized:
            return None, None

        try:
            binary = self.preprocess_image(img)
            digit_images = self.segment_digits(binary)

            if not digit_images:
                return None, None

            result = "".join(
                [
                    label
                    for digit_img in digit_images
                    if (label := self.recognize_digit(digit_img)[0])
                ]
            )

            if "/" in result:
                parts = result.split("/", 1)
                if len(parts) == 2:
                    try:
                        current = int(parts[0].replace(",", ""))
                        maximum = int(parts[1].replace(",", ""))
                        return current, maximum
                    except ValueError:
                        pass
            return None, None

        except Exception as e:
            print(f"âŒ æ¨¡æ¿è§£æå¤±è´¥: {e}")
            return None, None


_recognizer_cache = {}


def get_recognizer(engine: str = "keras"):
    """è·å–è¯†åˆ«å™¨å®ä¾‹
    
    Args:
        engine: å¼•æ“ç±»å‹ï¼Œæ”¯æŒ 'keras' æˆ– 'template'
    """
    if engine not in _recognizer_cache:
        if engine == "keras":
            recognizer = KerasDigitRecognizer()
            if not recognizer.initialize():
                return None
            _recognizer_cache["keras"] = recognizer
        elif engine == "template":
            recognizer = TemplateDigitRecognizer()
            if not recognizer.initialize():
                return None
            _recognizer_cache["template"] = recognizer
        elif engine == "tesseract":
            raise NotImplementedError("Tesseractå¼•æ“è¯·ç›´æ¥ä½¿ç”¨TesseractOcrManager")
        else:
            raise ValueError(f"æœªçŸ¥å¼•æ“: {engine}ï¼Œæ”¯æŒ 'keras' æˆ– 'template'")
    return _recognizer_cache.get(engine)


if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("ç”¨æ³•: python recognizer.py <image_path>")
        sys.exit(1)

    recognizer = get_recognizer("keras")
    if not recognizer:
        sys.exit(1)

    img = cv2.imread(sys.argv[1])
    if img is None:
        print(f"âŒ æ— æ³•åŠ è½½å›¾åƒ: {sys.argv[1]}")
        sys.exit(1)

    current, maximum = recognizer.recognize_and_parse(img)
    print(f"è¯†åˆ«ç»“æœ: {current}/{maximum}" if current is not None else "âŒ è¯†åˆ«å¤±è´¥")
